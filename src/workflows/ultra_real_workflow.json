{
    "input": {
      "uid": "test_input",
      "customModles":[],
      "customNodes":[],
    "images": [],
    "workflow":{
    "59": {
      "inputs": {
        "samples": [
          "112",
          0
        ],
        "vae": [
          "89",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "67": {
      "inputs": {
        "images": [
          "59",
          0
        ]
      },
      "class_type": "PreviewImage",
      "_meta": {
        "title": "Preview Image"
      }
    },
    "84": {
      "inputs": {
        "unet_name": "ultra_real_fine_tune.safetensors",
        "weight_dtype": "default"
      },
      "class_type": "UNETLoader",
      "_meta": {
        "title": "Load Diffusion Model"
      }
    },
    "85": {
      "inputs": {
        "noise_seed": 123169969974844
      },
      "class_type": "RandomNoise",
      "_meta": {
        "title": "RandomNoise"
      }
    },
    "86": {
      "inputs": {
        "sampler_name": "dpmpp_2m_sde"
      },
      "class_type": "KSamplerSelect",
      "_meta": {
        "title": "KSamplerSelect"
      }
    },
    "89": {
      "inputs": {
        "vae_name": "ae.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "90": {
      "inputs": {
        "clip_name1": "clip_l.safetensors",
        "clip_name2": "t5xxl_fp16.safetensors",
        "type": "flux",
        "device": "default"
      },
      "class_type": "DualCLIPLoader",
      "_meta": {
        "title": "DualCLIPLoader"
      }
    },
    "91": {
      "inputs": {
        "width": 768,
        "height": 1024,
        "batch_size": 1
      },
      "class_type": "EmptySD3LatentImage",
      "_meta": {
        "title": "EmptySD3LatentImage"
      }
    },
    "92": {
      "inputs": {
        "PowerLoraLoaderHeaderWidget": {
          "type": "PowerLoraLoaderHeaderWidget"
        },
        "lora_1": {
          "on": true,
          "lora": "flux_lora.safetensors",
          "strength": 1
        },
        "lora_2": {
          "on": true,
          "lora": "iphone_lora.safetensors",
          "strength": 0.75
        },
        "lora_3": {
          "on": false,
          "lora": "realism_amplifier.safetensors",
          "strength": 0.5
        },
        "lora_4": {
          "on": true,
          "lora": "35mm_joycap.safetensors",
          "strength": 1
        },
        "lora_5": {
          "on": true,
          "lora": "hands_detailer.safetensors",
          "strength": 1
        },
        "➕ Add Lora": "",
        "model": [
          "84",
          0
        ],
        "clip": [
          "90",
          0
        ]
      },
      "class_type": "Power Lora Loader (rgthree)",
      "_meta": {
        "title": "Power Lora Loader (rgthree)"
      }
    },
    "93": {
      "inputs": {
        "max_shift": 1.1500000000000001,
        "base_shift": 0.5000000000000001,
        "width": 768,
        "height": 1024,
        "model": [
          "92",
          0
        ]
      },
      "class_type": "ModelSamplingFlux",
      "_meta": {
        "title": "ModelSamplingFlux"
      }
    },
    "94": {
      "inputs": {
        "text": "A man walking along a sidewalk holding a phone to his ear with one hand, the other hand gesturing as he speaks. Full‑body visible from head to toe, photorealistic skin tones and hand anatomy, soft overcast lighting for even illumination",
        "clip": [
          "92",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "95": {
      "inputs": {
        "scheduler": "simple",
        "steps": 30,
        "denoise": 1,
        "model": [
          "93",
          0
        ]
      },
      "class_type": "BasicScheduler",
      "_meta": {
        "title": "BasicScheduler"
      }
    },
    "96": {
      "inputs": {
        "guidance": 5.5,
        "conditioning": [
          "94",
          0
        ]
      },
      "class_type": "FluxGuidance",
      "_meta": {
        "title": "FluxGuidance"
      }
    },
    "97": {
      "inputs": {
        "model": [
          "93",
          0
        ],
        "conditioning": [
          "96",
          0
        ]
      },
      "class_type": "BasicGuider",
      "_meta": {
        "title": "BasicGuider"
      }
    },
    "98": {
      "inputs": {
        "noise": [
          "85",
          0
        ],
        "guider": [
          "97",
          0
        ],
        "sampler": [
          "86",
          0
        ],
        "sigmas": [
          "95",
          0
        ],
        "latent_image": [
          "91",
          0
        ]
      },
      "class_type": "SamplerCustomAdvanced",
      "_meta": {
        "title": "SamplerCustomAdvanced"
      }
    },
    "99": {
      "inputs": {
        "samples": [
          "98",
          0
        ],
        "vae": [
          "89",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "100": {
      "inputs": {
        "images": [
          "99",
          0
        ]
      },
      "class_type": "PreviewImage",
      "_meta": {
        "title": "Preview Image"
      }
    },
    "103": {
      "inputs": {
        "noise_seed": 197816674893528
      },
      "class_type": "RandomNoise",
      "_meta": {
        "title": "RandomNoise"
      }
    },
    "104": {
      "inputs": {
        "sampler_name": "dpmpp_2m_sde"
      },
      "class_type": "KSamplerSelect",
      "_meta": {
        "title": "KSamplerSelect"
      }
    },
    "105": {
      "inputs": {
        "PowerLoraLoaderHeaderWidget": {
          "type": "PowerLoraLoaderHeaderWidget"
        },
        "lora_1": {
          "on": true,
          "lora": "realism_amplifier.safetensors",
          "strength": 0.28
        },
        "lora_2": {
          "on": true,
          "lora": "ultra-real_lora.safetensors",
          "strength": 0.65
        },
        "lora_3": {
          "on": true,
          "lora": "face_detailer.safetensors",
          "strength": 1
        },
        "➕ Add Lora": "",
        "model": [
          "84",
          0
        ],
        "clip": [
          "90",
          0
        ]
      },
      "class_type": "Power Lora Loader (rgthree)",
      "_meta": {
        "title": "Power Lora Loader (rgthree)"
      }
    },
    "106": {
      "inputs": {
        "text": "A man walking along a sidewalk holding a phone to his ear with one hand, the other hand gesturing as he speaks. Full‑body visible from head to toe, photorealistic skin tones and hand anatomy, soft overcast lighting for even illumination",
        "clip": [
          "105",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "107": {
      "inputs": {
        "max_shift": 0,
        "base_shift": 0.5000000000000001,
        "width": 16,
        "height": 1024,
        "model": [
          "105",
          0
        ]
      },
      "class_type": "ModelSamplingFlux",
      "_meta": {
        "title": "ModelSamplingFlux"
      }
    },
    "108": {
      "inputs": {
        "guidance": 3.5,
        "conditioning": [
          "106",
          0
        ]
      },
      "class_type": "FluxGuidance",
      "_meta": {
        "title": "FluxGuidance"
      }
    },
    "109": {
      "inputs": {
        "scheduler": "simple",
        "steps": 28,
        "denoise": 0.7000000000000002,
        "model": [
          "107",
          0
        ]
      },
      "class_type": "BasicScheduler",
      "_meta": {
        "title": "BasicScheduler"
      }
    },
    "110": {
      "inputs": {
        "model": [
          "107",
          0
        ],
        "conditioning": [
          "108",
          0
        ]
      },
      "class_type": "BasicGuider",
      "_meta": {
        "title": "BasicGuider"
      }
    },
    "111": {
      "inputs": {
        "pixels": [
          "99",
          0
        ],
        "vae": [
          "89",
          0
        ]
      },
      "class_type": "VAEEncode",
      "_meta": {
        "title": "VAE Encode"
      }
    },
    "112": {
      "inputs": {
        "noise": [
          "103",
          0
        ],
        "guider": [
          "110",
          0
        ],
        "sampler": [
          "104",
          0
        ],
        "sigmas": [
          "109",
          0
        ],
        "latent_image": [
          "111",
          0
        ]
      },
      "class_type": "SamplerCustomAdvanced",
      "_meta": {
        "title": "SamplerCustomAdvanced"
      }
    },
    "117": {
      "inputs": {
        "filename_prefix": "final",
        "images": [
          "59",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    }
    }
  }
  }